{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from lazypredict.Supervised import LazyClassifier\n",
    "\n",
    "\n",
    "# X = pd.read_csv('data/X.csv')\n",
    "# y = pd.read_csv('data/y.csv')\n",
    "\n",
    "# #train test split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # used for kaggle submission\n",
    "# X_kaggle = pd.read_csv('data/X_kaggle.csv')\n",
    "\n",
    "\n",
    "X = pd.read_csv('data/X_better.csv', header=None, sep=\";\").to_numpy()\n",
    "y = pd.read_csv('data/y_better.csv').to_numpy().ravel()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "X_kaggle = pd.read_csv('data/X_kaggle.csv', header=None).to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12960 candidates, totalling 38880 fits\n",
      "Best parameters found:  {'colsample_bytree': 0.5, 'eval_metric': 'mlogloss', 'gamma': 0, 'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 50, 'subsample': 0.6}\n",
      "Best (accuracy) score:  nan\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150, 200, 300],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'subsample': [0.6, 0.75, 0.9, 1],\n",
    "    'colsample_bytree': [0.5, 0.75, 0.8, 1.0],\n",
    "    'eval_metric': ['mlogloss', 'logloss'],\n",
    "    'gamma': [0, 0.1, 0.2],\n",
    "    'min_child_weight': [1, 3, 5]\n",
    "}\n",
    "\n",
    "def custom_score(y_true, y_pred):\n",
    "    class_1_ratio = np.mean(y_pred)\n",
    "    imbalance_penalty = np.abs(class_1_ratio - 0.5)\n",
    "    accuracy = np.mean(y_true == y_pred)\n",
    "    # you can change 10 to any other number to adjust the penality strength\n",
    "    return accuracy - imbalance_penalty*7\n",
    "\n",
    "acc5050 = make_scorer(custom_score)\n",
    "\n",
    "\n",
    "xgb_model = xgboost.XGBClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, \n",
    "                           scoring='accuracy', cv=3, verbose=1, n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "# dependent on scoring function not actually the acurracy but the custom score including imbalance penalty\n",
    "print(\"Best (accuracy) score: \", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.8806818181818182\n"
     ]
    }
   ],
   "source": [
    "y_pred_test_xgb = grid_search.best_estimator_.predict(X_test)\n",
    "print(f\"Accuracy on test set: {accuracy_score(y_test, y_pred_test_xgb)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions\n",
      "0    746\n",
      "1    720\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "y_scores = grid_search.best_estimator_.predict_proba(X_kaggle)[:, 1]\n",
    "\n",
    "sorted_scores = np.sort(y_scores)\n",
    "threshold_index = int(len(sorted_scores) * 0.51)\n",
    "threshold = sorted_scores[threshold_index]\n",
    "\n",
    "y_pred_thresholded = (y_scores >= threshold).astype(int)\n",
    "\n",
    "y_pred_thresholded = pd.DataFrame(y_pred_thresholded, columns=['predictions'])\n",
    "y_pred_thresholded[\"ID\"] = y_pred_thresholded.index\n",
    "print(y_pred_thresholded[\"predictions\"].value_counts())\n",
    "y_pred_thresholded.to_csv('data/thresholding_y_xgb.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xgb = grid_search.best_estimator_.predict(X_kaggle)\n",
    "y_pred_xgb = pd.DataFrame(y_pred_xgb, columns=['predictions'])\n",
    "y_pred_xgb[\"ID\"] = y_pred_xgb.index\n",
    "y_pred_xgb.to_csv('data/y_pred_xgb_try.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8810872027180068"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_xgb = f1_score(y_test, y_pred_test_xgb)\n",
    "f1_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predictions\n",
       "0    767\n",
       "1    699\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_xgb[\"predictions\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LazyClassifier ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check which top 10 models are the best performing and furtherly train them ourselves with more delicate steps, meaning GridSearch and kFold :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_score(y_true, y_pred):\n",
    "    class_1_ratio = np.mean(y_pred)\n",
    "    imbalance_penalty = np.abs(class_1_ratio - 0.5)\n",
    "    accuracy = np.mean(y_true == y_pred)\n",
    "    # you can change 10 to any other number to adjust the penality strength\n",
    "    score = accuracy - imbalance_penalty*7\n",
    "    return score\n",
    "\n",
    "acc5050 = make_scorer(custom_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 29/29 [00:30<00:00,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 5280, number of negative: 5280\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001795 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4024\n",
      "[LightGBM] [Info] Number of data points in the train set: 10560, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "                               Accuracy  Balanced Accuracy  ROC AUC  F1 Score  \\\n",
      "Model                                                                           \n",
      "LGBMClassifier                     0.90               0.90     0.90      0.90   \n",
      "XGBClassifier                      0.90               0.90     0.90      0.90   \n",
      "SVC                                0.89               0.89     0.89      0.89   \n",
      "ExtraTreesClassifier               0.89               0.89     0.89      0.89   \n",
      "RandomForestClassifier             0.89               0.89     0.89      0.89   \n",
      "BaggingClassifier                  0.89               0.89     0.89      0.89   \n",
      "LogisticRegression                 0.88               0.88     0.88      0.88   \n",
      "AdaBoostClassifier                 0.88               0.88     0.88      0.88   \n",
      "KNeighborsClassifier               0.88               0.88     0.88      0.88   \n",
      "CalibratedClassifierCV             0.88               0.88     0.88      0.88   \n",
      "LinearSVC                          0.88               0.88     0.88      0.88   \n",
      "SGDClassifier                      0.88               0.88     0.88      0.87   \n",
      "LinearDiscriminantAnalysis         0.87               0.87     0.87      0.87   \n",
      "RidgeClassifierCV                  0.87               0.87     0.87      0.87   \n",
      "RidgeClassifier                    0.87               0.87     0.87      0.87   \n",
      "NuSVC                              0.86               0.86     0.86      0.86   \n",
      "LabelSpreading                     0.86               0.86     0.86      0.86   \n",
      "LabelPropagation                   0.86               0.86     0.86      0.86   \n",
      "ExtraTreeClassifier                0.85               0.85     0.85      0.85   \n",
      "DecisionTreeClassifier             0.84               0.84     0.84      0.84   \n",
      "PassiveAggressiveClassifier        0.84               0.84     0.84      0.84   \n",
      "QuadraticDiscriminantAnalysis      0.82               0.82     0.82      0.82   \n",
      "NearestCentroid                    0.82               0.82     0.82      0.82   \n",
      "BernoulliNB                        0.80               0.80     0.80      0.80   \n",
      "Perceptron                         0.79               0.79     0.79      0.79   \n",
      "GaussianNB                         0.77               0.77     0.77      0.77   \n",
      "DummyClassifier                    0.50               0.50     0.50      0.33   \n",
      "\n",
      "                               accuracy_score  Time Taken  \n",
      "Model                                                      \n",
      "LGBMClassifier                           0.90        0.22  \n",
      "XGBClassifier                            0.90        0.26  \n",
      "SVC                                      0.89        2.87  \n",
      "ExtraTreesClassifier                     0.89        1.16  \n",
      "RandomForestClassifier                   0.89        2.88  \n",
      "BaggingClassifier                        0.89        1.26  \n",
      "LogisticRegression                       0.88        0.10  \n",
      "AdaBoostClassifier                       0.88        0.92  \n",
      "KNeighborsClassifier                     0.88        0.10  \n",
      "CalibratedClassifierCV                   0.88        0.29  \n",
      "LinearSVC                                0.88        1.48  \n",
      "SGDClassifier                            0.88        0.13  \n",
      "LinearDiscriminantAnalysis               0.87        0.11  \n",
      "RidgeClassifierCV                        0.87        0.04  \n",
      "RidgeClassifier                          0.87        0.03  \n",
      "NuSVC                                    0.86        8.16  \n",
      "LabelSpreading                           0.86        6.05  \n",
      "LabelPropagation                         0.86        3.48  \n",
      "ExtraTreeClassifier                      0.85        0.04  \n",
      "DecisionTreeClassifier                   0.84        0.21  \n",
      "PassiveAggressiveClassifier              0.84        0.04  \n",
      "QuadraticDiscriminantAnalysis            0.82        0.03  \n",
      "NearestCentroid                          0.82        0.04  \n",
      "BernoulliNB                              0.80        0.03  \n",
      "Perceptron                               0.79        0.03  \n",
      "GaussianNB                               0.77        0.03  \n",
      "DummyClassifier                          0.50        0.04  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=accuracy_score)\n",
    "models, predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
    "\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "Best parameters found:  {'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Best (accuracy) score:  0.7857954545454547\n",
      "Accuracy on test set: 0.8890151515151515\n"
     ]
    }
   ],
   "source": [
    "# ditch acc5050, do it again with 'accuracy'\n",
    "\n",
    "# Define the parameter grid\n",
    "# kf = KFold(n_splits=5)\n",
    "\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "def custom_score(y_true, y_pred):\n",
    "    class_1_ratio = np.mean(y_pred)\n",
    "    imbalance_penalty = np.abs(class_1_ratio - 0.5)\n",
    "    accuracy = np.mean(y_true == y_pred)\n",
    "    # you can change 10 to any other number to adjust the penality strength\n",
    "    return accuracy - imbalance_penalty*7\n",
    "\n",
    "acc5050 = make_scorer(custom_score)\n",
    "\n",
    "# Initialize the Random Forest\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search_rf = GridSearchCV(\n",
    "    estimator=rf_model, \n",
    "    param_grid=param_grid_rf, \n",
    "    scoring=acc5050, \n",
    "    cv=5, \n",
    "    verbose=1, \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best parameters found: \", grid_search_rf.best_params_)\n",
    "# dependent on scoring function not actually the acurracy but the custom score including imbalance penalty\n",
    "print(\"Best (accuracy) score: \", grid_search_rf.best_score_)\n",
    "\n",
    "y_pred_test_rf = grid_search_rf.best_estimator_.predict(X_test)\n",
    "print(f\"Accuracy on test set: {accuracy_score(y_test, y_pred_test_rf)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution after thresholding: [729 736]\n"
     ]
    }
   ],
   "source": [
    "y_scores_rf = grid_search_rf.best_estimator_.predict_proba(X_kaggle)[:,1]\n",
    "\n",
    "sorted_scores_rf = np.sort(y_scores_rf)\n",
    "threshold_index_rf = int(len(sorted_scores_rf) * 0.5)\n",
    "threshold_rf = sorted_scores_rf[threshold_index_rf]\n",
    "\n",
    "y_pred_thresholded_rf = (y_scores_rf >= threshold_rf).astype(int)\n",
    "\n",
    "print(f\"Class distribution after thresholding: {np.bincount(y_pred_thresholded_rf)}\")\n",
    "\n",
    "y_pred_thresholded_rf = pd.DataFrame(y_pred_thresholded_rf, columns=['predictions'])\n",
    "y_pred_thresholded_rf[\"ID\"] = y_pred_thresholded_rf.index\n",
    "\n",
    "y_pred_rf = grid_search_rf.best_estimator_.predict(X_kaggle)\n",
    "y_pred_rf = pd.DataFrame(y_pred_rf, columns=['predictions'])\n",
    "y_pred_rf[\"ID\"] = y_pred_rf.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predictions\n",
       "1    736\n",
       "0    729\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_thresholded_rf.to_csv('data/thresholding_rf_y.csv', index=False)\n",
    "y_pred_thresholded_rf['predictions'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf.to_csv('data/y_pred_rf_new.csv', index=False)\n",
    "y_pred_rf['predictions'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_rf = f1_score(y_test, y_pred_test_rf)\n",
    "print(f\"F1-score on test set: {f1_rf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ExtraTreesClassifier ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "0.7375\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1460</th>\n",
       "      <td>0</td>\n",
       "      <td>1460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1461</th>\n",
       "      <td>1</td>\n",
       "      <td>1461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1462</th>\n",
       "      <td>0</td>\n",
       "      <td>1462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1463</th>\n",
       "      <td>0</td>\n",
       "      <td>1463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1464</th>\n",
       "      <td>1</td>\n",
       "      <td>1464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1465 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      prediction    ID\n",
       "0              1     0\n",
       "1              0     1\n",
       "2              0     2\n",
       "3              1     3\n",
       "4              0     4\n",
       "...          ...   ...\n",
       "1460           0  1460\n",
       "1461           1  1461\n",
       "1462           0  1462\n",
       "1463           0  1463\n",
       "1464           1  1464\n",
       "\n",
       "[1465 rows x 2 columns]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid_etc = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "def custom_score(y_true, y_pred):\n",
    "    class_1_ratio = np.mean(y_pred)\n",
    "    imbalance_penalty = np.abs(class_1_ratio - 0.5)\n",
    "    accuracy = np.mean(y_true == y_pred)\n",
    "    # you can change 10 to any other number to adjust the penality strength\n",
    "    return accuracy - imbalance_penalty*7\n",
    "\n",
    "acc5050 = make_scorer(custom_score)\n",
    "\n",
    "# Initialize the ExtraTreeClassifier\n",
    "etc_model = ExtraTreesClassifier(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search_etc = GridSearchCV(estimator=etc_model, param_grid=param_grid_etc, cv=kf, scoring=acc5050, verbose=1)\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search_etc.fit(X_train, y_train)\n",
    "\n",
    "best_etc_model = grid_search_etc.best_estimator_\n",
    "print(grid_search_etc.best_score_)\n",
    "\n",
    "y_pred_etc = best_etc_model.predict(X_kaggle)\n",
    "\n",
    "y_pred_etc = pd.DataFrame(y_pred_etc, columns=['prediction'])\n",
    "y_pred_etc['ID'] = y_pred_etc.index\n",
    "y_pred_etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.8878787878787879\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8899628252788104"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test_etc = grid_search_etc.best_estimator_.predict(X_test)\n",
    "print(f\"Accuracy on test set: {accuracy_score(y_test, y_pred_test_etc)}\")\n",
    "\n",
    "f1_etc = f1_score(y_test, y_pred_test_etc)\n",
    "f1_etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBMClassifier ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n",
      "[LightGBM] [Info] Number of positive: 5280, number of negative: 5280\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001484 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4064\n",
      "[LightGBM] [Info] Number of data points in the train set: 10560, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Best parameters found:  {'colsample_bytree': 0.8, 'learning_rate': 0.2, 'n_estimators': 200, 'num_leaves': 25, 'subsample': 0.8}\n",
      "Best (accuracy) score:  0.7761363636363635\n",
      "Accuracy on test set: 0.8992424242424243\n"
     ]
    }
   ],
   "source": [
    "param_grid_lgb = {\n",
    "    'num_leaves': [25, 30, 50],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "def custom_score(y_true, y_pred):\n",
    "    class_1_ratio = np.mean(y_pred)\n",
    "    imbalance_penalty = np.abs(class_1_ratio - 0.5)\n",
    "    accuracy = np.mean(y_true == y_pred)\n",
    "    # you can change 10 to any other number to adjust the penality strength\n",
    "    return accuracy - imbalance_penalty*7\n",
    "\n",
    "acc5050 = make_scorer(custom_score)\n",
    "\n",
    "# Initialize the LGBMClassifier\n",
    "lgb_model = lgb.LGBMClassifier(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search_lgb = GridSearchCV(\n",
    "    estimator=lgb_model, \n",
    "    param_grid=param_grid_lgb, \n",
    "    scoring=acc5050, \n",
    "    cv=3, \n",
    "    verbose=1, \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search_lgb.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best parameters found: \", grid_search_lgb.best_params_)\n",
    "# dependent on scoring function not actually the acurracy but the custom score including imbalance penalty\n",
    "print(\"Best (accuracy) score: \", grid_search_lgb.best_score_)\n",
    "\n",
    "y_pred_test_lgb = grid_search_lgb.best_estimator_.predict(X_test)\n",
    "print(f\"Accuracy on test set: {accuracy_score(y_test, y_pred_test_lgb)}\")\n",
    "\n",
    "y_pred_lgb = grid_search_lgb.best_estimator_.predict(X_kaggle)\n",
    "y_pred_lgb = pd.DataFrame(y_pred_lgb, columns=['predictions'])\n",
    "y_pred_lgb[\"ID\"] = y_pred_lgb.index\n",
    "# y_pred_lgb.to_csv('data/y_pred_lgb.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution after thresholding: [732 733]\n"
     ]
    }
   ],
   "source": [
    "y_scores_lgb = grid_search_lgb.best_estimator_.predict_proba(X_kaggle)[:, 1]\n",
    "\n",
    "sorted_scores_lgm = np.sort(y_scores_lgb)\n",
    "threshold_index_lgm = int(len(sorted_scores_lgm) * 0.5)\n",
    "threshold_lgm = sorted_scores_lgm[threshold_index_lgm]\n",
    "\n",
    "y_pred_thresholded_lgm = (y_scores_lgb >= threshold_lgm).astype(int)\n",
    "\n",
    "print(f\"Class distribution after thresholding: {np.bincount(y_pred_thresholded_lgm)}\")\n",
    "\n",
    "y_pred_thresholded_lgm = pd.DataFrame(y_pred_thresholded_lgm, columns=['predictions'])\n",
    "y_pred_thresholded_lgm[\"ID\"] = y_pred_thresholded_lgm.index\n",
    "\n",
    "y_pred_lgm = grid_search_lgb.best_estimator_.predict(X_kaggle)\n",
    "y_pred_lgm = pd.DataFrame(y_pred_lgm, columns=['predictions'])\n",
    "y_pred_lgm[\"ID\"] = y_pred_lgm.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predictions\n",
       "0    795\n",
       "1    670\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_lgb['predictions'].value_counts()\n",
    "\n",
    "#y_pred_lgb.to_csv('y_pred_lgb.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score on test set: 0.9007462686567165\n"
     ]
    }
   ],
   "source": [
    "f1_lgm = f1_score(y_test, y_pred_test_lgb)\n",
    "print(f\"F1-score on test set: {f1_lgm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_thresholded_lgm.to_csv('data/thresholding_lgm_y.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoostClassifier ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n",
      "0.7312499999999997\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1461</th>\n",
       "      <td>0</td>\n",
       "      <td>1461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1462</th>\n",
       "      <td>1</td>\n",
       "      <td>1462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1463</th>\n",
       "      <td>0</td>\n",
       "      <td>1463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1464</th>\n",
       "      <td>0</td>\n",
       "      <td>1464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465</th>\n",
       "      <td>1</td>\n",
       "      <td>1465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1466 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      prediction    ID\n",
       "0              0     0\n",
       "1              1     1\n",
       "2              0     2\n",
       "3              0     3\n",
       "4              1     4\n",
       "...          ...   ...\n",
       "1461           0  1461\n",
       "1462           1  1462\n",
       "1463           0  1463\n",
       "1464           0  1464\n",
       "1465           1  1465\n",
       "\n",
       "[1466 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid_ada = {\n",
    "    'learning_rate': [0.01, 0.1, 0.5, 1.0],\n",
    "    'n_estimators': [50, 100, 200, 300],\n",
    "    'algorithm': ['SAMME', 'SAMME.R'],\n",
    "}\n",
    "\n",
    "def custom_score(y_true, y_pred):\n",
    "    class_1_ratio = np.mean(y_pred)\n",
    "    imbalance_penalty = np.abs(class_1_ratio - 0.5)\n",
    "    accuracy = np.mean(y_true == y_pred)\n",
    "    # you can change 10 to any other number to adjust the penality strength\n",
    "    return accuracy - imbalance_penalty*7\n",
    "\n",
    "acc5050 = make_scorer(custom_score)\n",
    "\n",
    "# Initialize the AdaBoostClassifier\n",
    "ada_model = AdaBoostClassifier(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search_ada = GridSearchCV(estimator=ada_model, param_grid=param_grid_ada, cv=3, scoring=acc5050, verbose=1)\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search_ada.fit(X_train, y_train)\n",
    "\n",
    "best_ada_model = grid_search_ada.best_estimator_\n",
    "print(grid_search_ada.best_score_)\n",
    "\n",
    "y_pred_ada = best_ada_model.predict(X_kaggle)\n",
    "\n",
    "y_pred_ada = pd.DataFrame(y_pred_ada, columns=['prediction'])\n",
    "y_pred_ada['ID'] = y_pred_ada.index\n",
    "y_pred_ada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.8852272727272728\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8874860750092833"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test_ada = grid_search_ada.best_estimator_.predict(X_test)\n",
    "print(f\"Accuracy on test set: {accuracy_score(y_test, y_pred_test_ada)}\")\n",
    "\n",
    "f1_ada = f1_score(y_test, y_pred_test_ada)\n",
    "f1_ada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predictions\n",
       "1    749\n",
       "0    717\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_ada = grid_search_ada.best_estimator_.predict(X_kaggle)\n",
    "y_pred_ada = pd.DataFrame(y_pred_ada, columns=['predictions'])\n",
    "y_pred_ada[\"ID\"] = y_pred_ada.index\n",
    "y_pred_ada.value_counts(\"predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ada.to_csv('data/ada.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution after thresholding: [733 733]\n"
     ]
    }
   ],
   "source": [
    "y_scores = grid_search_ada.best_estimator_.predict_proba(X_kaggle)[:, 1]\n",
    "\n",
    "sorted_scores = np.sort(y_scores)\n",
    "threshold_index = int(len(sorted_scores) * 0.5)\n",
    "threshold = sorted_scores[threshold_index]\n",
    "\n",
    "y_pred_thresholded = (y_scores >= threshold).astype(int)\n",
    "\n",
    "print(f\"Class distribution after thresholding: {np.bincount(y_pred_thresholded)}\")\n",
    "\n",
    "y_pred_thresholded = pd.DataFrame(y_pred_thresholded, columns=['predictions'])\n",
    "y_pred_thresholded[\"ID\"] = y_pred_thresholded.index\n",
    "y_pred_thresholded.to_csv('data/thresholding_y_ada.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final files to submit (per model) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "y_pred_xgb.to_csv('data/y_pred_xgb.csv', index=False)\n",
    "\n",
    "# Ramdom Forest\n",
    "y_pred_rf.to_csv('data/y_pred_rf.csv', index=False)\n",
    "\n",
    "# LightGBM\n",
    "y_pred_lgb.to_csv('data/y_pred_lgb.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
