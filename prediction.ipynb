{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# first try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "\n",
    "\n",
    "# X = pd.read_csv('data/X.csv')\n",
    "# y = pd.read_csv('data/y.csv')\n",
    "\n",
    "# #train test split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # used for kaggle submission\n",
    "# X_kaggle = pd.read_csv('data/X_kaggle.csv')\n",
    "\n",
    "\n",
    "X = pd.read_csv('data/X.csv').to_numpy()\n",
    "y = pd.read_csv('data/y.csv').to_numpy().ravel()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "X_kaggle = pd.read_csv('data/X_kaggle.csv').to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Best GridSearchCV Score on Training Data: 0.9271885521885522\n",
      "Accuracy on Validation Set: 0.9345959595959596\n",
      "Accuracy on Test Set: 0.927020202020202\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import xgboost\n",
    "\n",
    "# Load the data\n",
    "X = pd.read_csv('data/X.csv')\n",
    "y = pd.read_csv('data/y.csv')\n",
    "\n",
    "# Train, validation, and test split (60% train, 20% validation, 20% test)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)  # 60% train\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)  # 20% val, 20% test\n",
    "\n",
    "# Used for Kaggle submission\n",
    "X_kaggle = pd.read_csv('data/X_kaggle.csv')\n",
    "\n",
    "# Define the parameter grid\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'random_state': [42],\n",
    "    'subsample': [0.8, 1]\n",
    "}\n",
    "\n",
    "# Initialize the XGBClassifier\n",
    "xgb_model = xgboost.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid_xgb, cv=kf, scoring='accuracy', verbose=1)\n",
    "\n",
    "# Fit GridSearchCV with training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best XGB model after GridSearch\n",
    "best_xgb_model = grid_search.best_estimator_\n",
    "print(f\"Best GridSearchCV Score on Training Data: {grid_search.best_score_}\")\n",
    "\n",
    "# Evaluate on the validation set to check for overfitting\n",
    "y_pred_val = best_xgb_model.predict(X_val)\n",
    "val_accuracy = accuracy_score(y_val, y_pred_val)\n",
    "print(f\"Accuracy on Validation Set: {val_accuracy}\")\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_test = best_xgb_model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "print(f\"Accuracy on Test Set: {test_accuracy}\")\n",
    "\n",
    "# Predict on the Kaggle dataset for submission\n",
    "y_pred_xgb = best_xgb_model.predict(X_kaggle)\n",
    "\n",
    "# Prepare submission file\n",
    "y_pred_xgb = pd.DataFrame(y_pred_xgb, columns=['prediction'])\n",
    "y_pred_xgb['ID'] = y_pred_xgb.index\n",
    "y_pred_xgb\n",
    "\n",
    "# Optional: Save predictions to CSV for submission\n",
    "y_pred_xgb.to_csv('y_pred_xgb.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction\n",
      "1    775\n",
      "0    691\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_pred_xgb['prediction'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1461</th>\n",
       "      <td>1</td>\n",
       "      <td>1461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1462</th>\n",
       "      <td>1</td>\n",
       "      <td>1462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1463</th>\n",
       "      <td>0</td>\n",
       "      <td>1463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1464</th>\n",
       "      <td>1</td>\n",
       "      <td>1464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465</th>\n",
       "      <td>1</td>\n",
       "      <td>1465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1466 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      prediction    ID\n",
       "0              0     0\n",
       "1              1     1\n",
       "2              1     2\n",
       "3              1     3\n",
       "4              0     4\n",
       "...          ...   ...\n",
       "1461           1  1461\n",
       "1462           1  1462\n",
       "1463           0  1463\n",
       "1464           1  1464\n",
       "1465           1  1465\n",
       "\n",
       "[1466 rows x 2 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the parameter grid\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'random_state': [42],\n",
    "    'subsample': [0.8, 1]\n",
    "}\n",
    "\n",
    "# Initialize the XGBClassifier\n",
    "xgb_model = xgboost.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_model.fit(X_train, y_train)\n",
    "# # Initialize GridSearchCV\n",
    "# grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid_xgb, cv=kf, scoring='accuracy', verbose=1)\n",
    "\n",
    "# # Fit GridSearchCV\n",
    "# grid_search.fit(X_train, y_train)\n",
    "# best_xgb_model = grid_search.best_estimator_\n",
    "# print(grid_search.best_score_)\n",
    "\n",
    "# # Predict on the test set\n",
    "# y_pred_test = best_xgb_model.predict(X_test)\n",
    "# accuracy = accuracy_score(y_test, y_pred_test)\n",
    "# print(f\"Accuracy on test set: {accuracy}\")\n",
    "\n",
    "y_pred_xgb = xgb_model.predict(X_kaggle)\n",
    "\n",
    "y_pred_xgb = pd.DataFrame(y_pred_xgb, columns=['prediction'])\n",
    "y_pred_xgb['ID'] = y_pred_xgb.index\n",
    "y_pred_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction\n",
      "1    791\n",
      "0    675\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_pred_xgb['prediction'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xgb.to_csv('y_pred_xgb2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LazyClassifier ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check which top 10 models are the best performing and furtherly train them ourselves with more delicate steps, meaning GridSearch and kFold :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_score(y_true, y_pred):\n",
    "    class_1_ratio = np.mean(y_pred)\n",
    "    imbalance_penalty = np.abs(class_1_ratio - 0.5)\n",
    "    accuracy = np.mean(y_true == y_pred)\n",
    "    # you can change 10 to any other number to adjust the penality strength\n",
    "    score = accuracy - imbalance_penalty*7\n",
    "    return score\n",
    "\n",
    "acc5050 = make_scorer(custom_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████████████████████████████████████▌ | 28/29 [01:54<00:11, 11.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 5280, number of negative: 5280\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017921 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2171\n",
      "[LightGBM] [Info] Number of data points in the train set: 10560, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 29/29 [02:37<00:00,  5.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               Accuracy  Balanced Accuracy  ROC AUC  F1 Score  \\\n",
      "Model                                                                           \n",
      "RandomForestClassifier             0.89               0.89     0.89      0.89   \n",
      "LGBMClassifier                     0.89               0.89     0.89      0.89   \n",
      "KNeighborsClassifier               0.89               0.89     0.89      0.89   \n",
      "ExtraTreesClassifier               0.89               0.89     0.89      0.89   \n",
      "XGBClassifier                      0.89               0.89     0.89      0.89   \n",
      "SVC                                0.88               0.88     0.88      0.88   \n",
      "LogisticRegression                 0.88               0.88     0.88      0.88   \n",
      "AdaBoostClassifier                 0.88               0.88     0.88      0.88   \n",
      "CalibratedClassifierCV             0.88               0.88     0.88      0.88   \n",
      "LinearSVC                          0.88               0.88     0.88      0.88   \n",
      "LinearDiscriminantAnalysis         0.88               0.88     0.88      0.88   \n",
      "RidgeClassifier                    0.88               0.88     0.88      0.88   \n",
      "RidgeClassifierCV                  0.88               0.88     0.88      0.88   \n",
      "SGDClassifier                      0.88               0.88     0.88      0.88   \n",
      "LabelSpreading                     0.87               0.87     0.87      0.87   \n",
      "LabelPropagation                   0.87               0.87     0.87      0.87   \n",
      "BaggingClassifier                  0.87               0.87     0.87      0.87   \n",
      "QuadraticDiscriminantAnalysis      0.87               0.87     0.87      0.87   \n",
      "NuSVC                              0.86               0.86     0.86      0.86   \n",
      "BernoulliNB                        0.85               0.85     0.85      0.85   \n",
      "NearestCentroid                    0.85               0.85     0.85      0.85   \n",
      "DecisionTreeClassifier             0.84               0.84     0.84      0.84   \n",
      "ExtraTreeClassifier                0.84               0.84     0.84      0.84   \n",
      "PassiveAggressiveClassifier        0.81               0.81     0.81      0.81   \n",
      "GaussianNB                         0.79               0.79     0.79      0.79   \n",
      "Perceptron                         0.79               0.79     0.79      0.79   \n",
      "DummyClassifier                    0.50               0.50     0.50      0.33   \n",
      "\n",
      "                               accuracy_score  Time Taken  \n",
      "Model                                                      \n",
      "RandomForestClassifier                   0.89        6.90  \n",
      "LGBMClassifier                           0.89       42.71  \n",
      "KNeighborsClassifier                     0.89        0.64  \n",
      "ExtraTreesClassifier                     0.89        2.74  \n",
      "XGBClassifier                            0.89       40.85  \n",
      "SVC                                      0.88        9.52  \n",
      "LogisticRegression                       0.88        0.51  \n",
      "AdaBoostClassifier                       0.88        1.93  \n",
      "CalibratedClassifierCV                   0.88        0.47  \n",
      "LinearSVC                                0.88        3.78  \n",
      "LinearDiscriminantAnalysis               0.88        0.33  \n",
      "RidgeClassifier                          0.88        0.10  \n",
      "RidgeClassifierCV                        0.88        0.45  \n",
      "SGDClassifier                            0.88        0.11  \n",
      "LabelSpreading                           0.87       12.52  \n",
      "LabelPropagation                         0.87        6.72  \n",
      "BaggingClassifier                        0.87        2.39  \n",
      "QuadraticDiscriminantAnalysis            0.87        0.65  \n",
      "NuSVC                                    0.86       22.79  \n",
      "BernoulliNB                              0.85        0.06  \n",
      "NearestCentroid                          0.85        0.13  \n",
      "DecisionTreeClassifier                   0.84        0.33  \n",
      "ExtraTreeClassifier                      0.84        0.10  \n",
      "PassiveAggressiveClassifier              0.81        0.11  \n",
      "GaussianNB                               0.79        0.10  \n",
      "Perceptron                               0.79        0.08  \n",
      "DummyClassifier                          0.50        0.06  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=accuracy_score)\n",
    "models, predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
    "\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "Best parameters found:  {'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Best (accuracy) score:  0.7617424242424243\n",
      "Accuracy on test set: 0.893560606060606\n"
     ]
    }
   ],
   "source": [
    "# ditch acc5050, do it again with 'accuracy'\n",
    "\n",
    "# Define the parameter grid\n",
    "# kf = KFold(n_splits=5)\n",
    "\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "def custom_score(y_true, y_pred):\n",
    "    class_1_ratio = np.mean(y_pred)\n",
    "    imbalance_penalty = np.abs(class_1_ratio - 0.5)\n",
    "    accuracy = np.mean(y_true == y_pred)\n",
    "    # you can change 10 to any other number to adjust the penality strength\n",
    "    return accuracy - imbalance_penalty*7\n",
    "\n",
    "acc5050 = make_scorer(custom_score)\n",
    "\n",
    "# Initialize the Random Forest\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search_rf = GridSearchCV(\n",
    "    estimator=rf_model, \n",
    "    param_grid=param_grid_rf, \n",
    "    scoring=acc5050, \n",
    "    cv=5, \n",
    "    verbose=1, \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best parameters found: \", grid_search_rf.best_params_)\n",
    "# dependent on scoring function not actually the acurracy but the custom score including imbalance penalty\n",
    "print(\"Best (accuracy) score: \", grid_search_rf.best_score_)\n",
    "\n",
    "y_pred_test_rf = grid_search_rf.best_estimator_.predict(X_test)\n",
    "print(f\"Accuracy on test set: {accuracy_score(y_test, y_pred_test_rf)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 11 features, but RandomForestClassifier is expecting 12 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/6f/_m3vtyy92m94t_l4qyl157240000gn/T/ipykernel_84698/3932519940.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_scores_rf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search_rf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_kaggle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msorted_scores_rf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_scores_rf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mthreshold_index_rf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted_scores_rf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mthreshold_rf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted_scores_rf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mthreshold_index_rf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    863\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         \u001b[0;31m# Check data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 865\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    866\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m         \u001b[0;31m# Assign chunk of trees to jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    597\u001b[0m         Validate X whenever one tries to predict, apply, predict_proba.\"\"\"\n\u001b[1;32m    598\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintc\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No support for np.int64 index based sparse matrices\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ensure_2d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    415\u001b[0m                 \u001b[0;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m                 \u001b[0;34mf\"is expecting {self.n_features_in_} features as input.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: X has 11 features, but RandomForestClassifier is expecting 12 features as input."
     ]
    }
   ],
   "source": [
    "y_scores_rf = grid_search_rf.best_estimator_.predict_proba(X_kaggle)[:, 1]\n",
    "\n",
    "sorted_scores_rf = np.sort(y_scores_rf)\n",
    "threshold_index_rf = int(len(sorted_scores_rf) * 0.5)\n",
    "threshold_rf = sorted_scores_rf[threshold_index_rf]\n",
    "\n",
    "y_pred_thresholded_rf = (y_scores_rf >= threshold_rf).astype(int)\n",
    "\n",
    "print(f\"Class distribution after thresholding: {np.bincount(y_pred_thresholded_rf)}\")\n",
    "\n",
    "y_pred_thresholded_rf = pd.DataFrame(y_pred_thresholded_rf, columns=['predictions'])\n",
    "y_pred_thresholded_rf[\"ID\"] = y_pred_thresholded_rf.index\n",
    "\n",
    "y_pred_rf = grid_search_rf.best_estimator_.predict(X_kaggle)\n",
    "y_pred_rf = pd.DataFrame(y_pred_rf, columns=['predictions'])\n",
    "y_pred_rf[\"ID\"] = y_pred_rf.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_thresholded_rf.to_csv('data/thresholding_rf_y.csv', index=False)\n",
    "y_pred_thresholded_rf['predictions'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf.to_csv('data/y_pred_rf_new.csv', index=False)\n",
    "y_pred_rf['predictions'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_rf = f1_score(y_test, y_pred_test_rf)\n",
    "f1_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ExtraTreesClassifier ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_etc = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "\n",
    "# Initialize the ExtraTreeClassifier\n",
    "etc_model = ExtraTreesClassifier(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search_etc = GridSearchCV(estimator=etc_model, param_grid=param_grid_etc, cv=kf, scoring=acc5050, verbose=1)\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search_etc.fit(X_train, y_train)\n",
    "\n",
    "best_etc_model = grid_search_etc.best_estimator_\n",
    "print(grid_search_etc.best_score_)\n",
    "\n",
    "y_pred_etc = best_etc_model.predict(X_kaggle)\n",
    "\n",
    "y_pred_etc = pd.DataFrame(y_pred_etc, columns=['prediction'])\n",
    "y_pred_etc['ID'] = y_pred_etc.index\n",
    "y_pred_etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test_etc = grid_search_etc.best_estimator_.predict(X_test)\n",
    "print(f\"Accuracy on test set: {accuracy_score(y_test, y_pred_test_etc)}\")\n",
    "\n",
    "f1_etc = f1_score(y_test, y_pred_test_etc)\n",
    "f1_etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBMClassifier ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_lgb = {\n",
    "    'num_leaves': [25, 30, 50],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "def custom_score(y_true, y_pred):\n",
    "    class_1_ratio = np.mean(y_pred)\n",
    "    imbalance_penalty = np.abs(class_1_ratio - 0.5)\n",
    "    accuracy = np.mean(y_true == y_pred)\n",
    "    # you can change 10 to any other number to adjust the penality strength\n",
    "    return accuracy - imbalance_penalty*7\n",
    "\n",
    "acc5050 = make_scorer(custom_score)\n",
    "\n",
    "# Initialize the LGBMClassifier\n",
    "lgb_model = lgb.LGBMClassifier(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search_lgb = GridSearchCV(\n",
    "    estimator=lgb_model, \n",
    "    param_grid=param_grid_lgb, \n",
    "    scoring=acc5050, \n",
    "    cv=3, \n",
    "    verbose=1, \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search_lgb.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best parameters found: \", grid_search_lgb.best_params_)\n",
    "# dependent on scoring function not actually the acurracy but the custom score including imbalance penalty\n",
    "print(\"Best (accuracy) score: \", grid_search_lgb.best_score_)\n",
    "\n",
    "y_pred_test_lgb = grid_search_lgb.best_estimator_.predict(X_test)\n",
    "print(f\"Accuracy on test set: {accuracy_score(y_test, y_pred_test_lgb)}\")\n",
    "\n",
    "y_pred_lgb = grid_search_lgb.best_estimator_.predict(X_kaggle)\n",
    "y_pred_lgb = pd.DataFrame(y_pred_lgb, columns=['predictions'])\n",
    "y_pred_lgb[\"ID\"] = y_pred_lgb.index\n",
    "# y_pred_lgb.to_csv('data/y_pred_lgb.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scores_lgb = grid_search_lgb.best_estimator_.predict_proba(X_kaggle)[:, 1]\n",
    "\n",
    "sorted_scores_lgm = np.sort(y_scores_lgb)\n",
    "threshold_index_lgm = int(len(sorted_scores_lgm) * 0.5)\n",
    "threshold_lgm = sorted_scores_lgm[threshold_index_lgm]\n",
    "\n",
    "y_pred_thresholded_lgm = (y_scores_lgb >= threshold_lgm).astype(int)\n",
    "\n",
    "print(f\"Class distribution after thresholding: {np.bincount(y_pred_thresholded_lgm)}\")\n",
    "\n",
    "y_pred_thresholded_lgm = pd.DataFrame(y_pred_thresholded_lgm, columns=['predictions'])\n",
    "y_pred_thresholded_lgm[\"ID\"] = y_pred_thresholded_lgm.index\n",
    "\n",
    "y_pred_lgm = grid_search_lgb.best_estimator_.predict(X_kaggle)\n",
    "y_pred_lgm = pd.DataFrame(y_pred_lgm, columns=['predictions'])\n",
    "y_pred_lgm[\"ID\"] = y_pred_lgm.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lgb['predictions'].value_counts()\n",
    "\n",
    "#y_pred_lgb.to_csv('y_pred_lgb.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_lgm = f1_score(y_test, y_pred_test_lgb)\n",
    "f1_lgm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_thresholded_lgm.to_csv('data/thresholding_lgm_y.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoostClassifier ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_ada = {\n",
    "    'learning_rate': [0.0001, 0.001, 0.01, 0.1, 1.0],\n",
    "    'n_estimators': [10, 50, 100, 500],\n",
    "}\n",
    "\n",
    "\n",
    "# Initialize the AdaBoostClassifier\n",
    "ada_model = AdaBoostClassifier(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search_ada = GridSearchCV(estimator=ada_model, param_grid=param_grid_ada, cv=kf, scoring='accuracy', verbose=1)\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search_ada.fit(X_train, y_train)\n",
    "\n",
    "best_ada_model = grid_search_ada.best_estimator_\n",
    "print(grid_search_ada.best_score_)\n",
    "\n",
    "y_pred_ada = best_ada_model.predict(X_kaggle)\n",
    "\n",
    "y_pred_ada = pd.DataFrame(y_pred_ada, columns=['prediction'])\n",
    "y_pred_ada['ID'] = y_pred_ada.index\n",
    "y_pred_ada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test_ada = grid_search_ada.best_estimator_.predict(X_test)\n",
    "print(f\"Accuracy on test set: {accuracy_score(y_test, y_pred_test_ada)}\")\n",
    "\n",
    "f1_ada = f1_score(y_test, y_pred_test_ada)\n",
    "f1_ada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"slay the boots down houston i'm deceased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final files to submit (per model) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "y_pred_xgb.to_csv('data/y_pred_xgb.csv', index=False)\n",
    "\n",
    "# Ramdom Forest\n",
    "y_pred_rf.to_csv('data/y_pred_rf.csv', index=False)\n",
    "\n",
    "# LightGBM\n",
    "y_pred_lgb.to_csv('data/y_pred_lgb.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
